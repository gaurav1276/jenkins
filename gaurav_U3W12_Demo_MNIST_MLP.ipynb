{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaurav1276/jenkins/blob/master/gaurav_U3W12_Demo_MNIST_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zSWyuZTlYS1"
      },
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRUhG-LzJux_"
      },
      "source": [
        "### Not for Grading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZPUeeN66kTn"
      },
      "source": [
        "<h2><b>Handwritten Digit Recognition</b></h2>\n",
        "<b> Problem Statement: </b> <br>\n",
        "The goal of this project is to create a model that will be able to recognize and determine the handwritten digits from its image by using ML/DL techniques and observe the performance difference between various techniques. <br>\n",
        "We use MNIST dataset for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKrpZC3S6kTy"
      },
      "source": [
        "<b>MNIST Dataset : </b> <br>\n",
        "The MNIST dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem.\n",
        "<br>\n",
        "\n",
        "The dataset was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). This is where the name for the dataset comes from, as the Modified NIST or MNIST dataset.\n",
        "Images of digits were taken from a variety of scanned documents, normalized in size and centered. This makes it an excellent dataset for evaluating models, allowing the developer to focus on the machine learning with very little data cleaning or preparation required.\n",
        "\n",
        "\n",
        "Each image is a 28 by 28 pixel square (784 pixels total). A standard split of the dataset is used to evaluate and compare models, where 60,000 images are used to train a model and a separate set of 10,000 images are used to test it.\n",
        "\n",
        "![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRI3O4ZwXEaF"
      },
      "source": [
        "## Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJNz2sDLoZ47"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maYkps60oZ48"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9wKhlWDsoZ48"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U3W12_Demo_MNIST_MLP\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx pip install torch\")\n",
        "    ipython.magic(\"sx pip install torchvision\")\n",
        "    ipython.magic(\"sx pip3 install torchviz\")\n",
        "    ipython.magic(\"sx wget -qq www.di.ens.fr/~lelarge/MNIST.tar.gz\")\n",
        "    ipython.magic(\"sx tar -zxvf MNIST.tar.gz\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "               \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required library"
      ],
      "metadata": {
        "id": "ryf_XFGswfWW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrxeHNNu6kT2"
      },
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"All libraries are loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fz0PNXCwhWg"
      },
      "source": [
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = MNIST(root = './', train=True, download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT63EXNUzSXK"
      },
      "source": [
        "print(len(train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLJBORVm6kUM"
      },
      "source": [
        "train_data, val_data = torch.utils.data.random_split(train_data, [50000, 10000])\n",
        "\n",
        "test_data = MNIST(root = './', train=False, download=True, transform=transform)\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
        "print(\"Training data created\")\n",
        "print(\"Train-Data length : \", len(train_data))\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "print(\"Validation data created\")\n",
        "print(\"Validation-Data length : \", len(val_data))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "print(\"Test data created\")\n",
        "print(\"Test-Data length : \", len(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKxpQMsr6kUf"
      },
      "source": [
        "print(\"Some of the training samples and their labels : \\n\")\n",
        "\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy()\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2,int(20/2), idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    # print out the correct label for each image\n",
        "    # .item() gets the value contained in a Tensor\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilr3GotJ6kUs"
      },
      "source": [
        "print (\"Pixel level View of one of the training sample \\n\")\n",
        "img = np.squeeze(images[1])\n",
        "fig = plt.figure(figsize = (12,12))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img, cmap='gray')\n",
        "width, height = img.shape\n",
        "thresh = img.max()/2.5\n",
        "for x in range(width):\n",
        "    for y in range(height):\n",
        "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "        ax.annotate(str(val), xy=(y,x),\n",
        "                    horizontalalignment='center',\n",
        "                    verticalalignment='center',\n",
        "                    color='white' if img[x][y]<thresh else 'black')\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbm-8HxIqvxR"
      },
      "source": [
        "### Initializing CUDA\n",
        "\n",
        "CUDA is used as an interface between our code and the GPU.\n",
        "\n",
        "Normally, we run the code in the CPU. To run it in the GPU, we need CUDA. Check if CUDA is available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHj_ZREiqvxU"
      },
      "source": [
        "# To test whether GPU instance is present in the system of not.\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Using PyTorch version:', torch.__version__, 'CUDA:', use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuGyWSz8q4NQ"
      },
      "source": [
        "If it's False, then we run the program on CPU. If it's True, then we run the program on GPU.\n",
        "\n",
        "Let us initialize some GPU-related variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_WeWksDqvxb"
      },
      "source": [
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2-9un3H2KnE"
      },
      "source": [
        "## Define the NN architecture\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)       # linear layer (n_hidden -> hidden_2)\n",
        "        self.fc3 = nn.Linear(512, 10)        # linear layer (n_hidden -> 10)\n",
        "        #self.dropout = nn.Dropout(0.2)       # dropout layer (p=0.2) # dropout prevents overfitting of data\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x)) # F.relu\n",
        "        return x\n",
        "\n",
        "# initialize the NN\n",
        "model = Net().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "wbomKrR02KnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "K_UpKROl2KnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size = (1,784), batch_size = -1)"
      ],
      "metadata": {
        "id": "FXvm1Wz62KnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IRb32R72KnJ"
      },
      "source": [
        "## Specify loss and optimization functions\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "print(criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LekhOKM2KnO"
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 20  # suggest training between 20-50 epochs\n",
        "\n",
        "model.train() # prep model for training\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    train_loss = 0.0                    # Initialize training, val loss\n",
        "    val_loss=0.0\n",
        "\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    for data, target in train_loader:\n",
        "        data=data.to(device)\n",
        "        target=target.to(device)\n",
        "        optimizer.zero_grad()            # clear the gradients of all optimized variables\n",
        "        output = model(data)             # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        loss = criterion(output, target) # calculate the loss\n",
        "        loss.backward()                  # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        optimizer.step()                 # perform a single optimization step (parameter update)\n",
        "        train_loss += loss.item()*data.size(0)  # update running training loss\n",
        "\n",
        "    for data, target in val_loader:\n",
        "        data=data.to(device)\n",
        "        target=target.to(device)\n",
        "        output = model(data)                  # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        loss = criterion(output, target)      # calculate the loss\n",
        "        val_loss += loss.item()*data.size(0)  # update running training loss\n",
        "\n",
        "    # print training statistics\n",
        "    train_loss = train_loss/len(train_loader.dataset)  # calculate average loss over an epoch\"\"\"\n",
        "    val_loss = val_loss/len(val_loader.dataset)        # Validation loss\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format( epoch+1, train_loss, val_loss ))\n",
        "    print(\"Training is done\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDrro8kA2KnQ"
      },
      "source": [
        "# Testing the  model\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval() # prep model for *evaluation*\n",
        "\n",
        "for data, target in test_loader:\n",
        "    data=data.to(device)\n",
        "    target=target.to(device)\n",
        "    output = model(data)                            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    loss = criterion(output, target)                # calculate the loss\n",
        "    test_loss += loss.item()*data.size(0)           # update test loss\n",
        "    _, pred = torch.max(output, 1)                  # convert output probabilities to predicted class\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))        # compare predictions to true label\n",
        "\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TQSSEjH2KnS"
      },
      "source": [
        "# obtain one batch of test images\n",
        "\n",
        "print(\"Test Images and their predicted labels : \\n\")\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "\n",
        "_, preds = torch.max(output, 1)  # convert output probabilities to predicted class\n",
        "images = images.cpu()        # prep images for display\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for Ungrading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}